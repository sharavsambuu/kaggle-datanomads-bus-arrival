{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bus_id_encoder     = pickle.load(open(\"./out/bus_id_encoder.pickle\"    , \"rb\"))\n",
    "route_id_encoder   = pickle.load(open(\"./out/route_id_encoder.pickle\"  , \"rb\"))\n",
    "busstop_id_encoder = pickle.load(open(\"./out/busstop_id_encoder.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummy_buses = [325819008, 451509115]\n",
    "print(\"bus ids\", dummy_buses)\n",
    "print(\"bus categorical ids\", bus_id_encoder.transform(dummy_buses))\n",
    "\n",
    "dummy_routes = [11100010, 11100012]\n",
    "print(\"route ids\", dummy_routes)\n",
    "print(\"route categorical ids\", route_id_encoder.transform(dummy_routes))\n",
    "\n",
    "dummy_busstops = [388, 112]\n",
    "print(\"busstop ids\", dummy_busstops)\n",
    "print(\"busstop categorical ids\", busstop_id_encoder.transform(dummy_busstops))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv(\"./out/cleaned_train.csv\")\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split_index = 2900000 # about 10%\n",
    "train_df    = dataset_df[:split_index]\n",
    "test_df     = dataset_df[split_index:]\n",
    "print(len(train_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_columns = [\n",
    "    'DAY_OF_WEEK'     ,\n",
    "    'HOUR_OF_DAY'     ,\n",
    "    'MINUTE_OF_HOUR'  ,\n",
    "    'SECOND_OF_MINUTE',\n",
    "    'TIME'            ,\n",
    "    'BUS_ID'          ,\n",
    "    'BUSROUTE_ID'     ,\n",
    "    'BUSSTOP_ID'      ,\n",
    "    'ROUTE_TIME'      ,\n",
    "    'SEQ_NUM'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_input = train_df[training_columns]\n",
    "train_label = train_df[['TIMESTAMP_DIFF']]\n",
    "\n",
    "test_input = test_df[training_columns]\n",
    "test_label = test_df[['TIMESTAMP_DIFF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(train_input.values, tf.float32),\n",
    "            tf.cast(train_label.values, tf.float32)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "testing_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(test_input.values, tf.float32),\n",
    "            tf.cast(test_label.values, tf.float32)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                        np.arange(d_model)[np.newaxis, :],\n",
    "                        d_model)\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_dim      = 151\n",
    "total_seconds = 18*3600 # 18hours\n",
    "pos_encoding  = positional_encoding(total_seconds, time_dim)\n",
    "print(pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, time_dim))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class BusNet(tf.keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(BusNet, self).__init__(**kwargs)\n",
    "\n",
    "        self.week          = [i for i in range(0, 7) ]\n",
    "        self.hours         = [i for i in range(0, 24)]\n",
    "        self.minutes       = [i for i in range(0, 60)]\n",
    "        self.seconds       = [i for i in range(0, 60)]\n",
    "        \n",
    "        \n",
    "        self.time_dim      = 151 # 7 days + 24 hours + 60 minutes + 60 seconds\n",
    "        self.time_count    = 18*3600\n",
    "\n",
    "        self.bus_dim       = 32\n",
    "        self.bus_count     = 1077\n",
    "\n",
    "        self.route_dim     = 32\n",
    "        self.route_count   = 353\n",
    "\n",
    "        self.busstop_dim   = 32\n",
    "        self.busstop_count = 1357\n",
    "\n",
    "        self.dropout_rate  = 0.1\n",
    "\n",
    "        self.days_of_week_matrix      = tf.one_hot(self.week   , len(self.week)   )\n",
    "        self.hours_of_day_matrix      = tf.one_hot(self.hours  , len(self.hours)  )\n",
    "        self.minutes_of_hour_matrix   = tf.one_hot(self.minutes, len(self.minutes))\n",
    "        self.seconds_of_minute_matrix = tf.one_hot(self.seconds, len(self.seconds))\n",
    "        self.time_position_matrix     = positional_encoding(self.time_count, self.time_dim)\n",
    "        \n",
    "        self.day_embedding     = tf.keras.layers.Embedding(len(self.week)    , len(self.week)   , weights=[self.days_of_week_matrix      ], trainable=False)\n",
    "        self.hour_embedding    = tf.keras.layers.Embedding(len(self.hours)   , len(self.hours)  , weights=[self.hours_of_day_matrix      ], trainable=False)\n",
    "        self.minute_embedding  = tf.keras.layers.Embedding(len(self.minutes) , len(self.minutes), weights=[self.minutes_of_hour_matrix   ], trainable=False)\n",
    "        self.second_embedding  = tf.keras.layers.Embedding(len(self.seconds) , len(self.seconds), weights=[self.seconds_of_minute_matrix ], trainable=False)\n",
    "        self.time_embedding    = tf.keras.layers.Embedding(self.time_count   , self.time_dim    , weights=[self.time_position_matrix[0]  ], trainable=True )\n",
    "        self.bus_embedding     = tf.keras.layers.Embedding(self.bus_count    , self.bus_dim     , embeddings_initializer='uniform')\n",
    "        self.route_embedding   = tf.keras.layers.Embedding(self.route_count  , self.route_dim   , embeddings_initializer='uniform')\n",
    "        self.busstop_embedding = tf.keras.layers.Embedding(self.busstop_count, self.busstop_dim , embeddings_initializer='uniform')\n",
    "\n",
    "        self.layer_1      = tf.keras.layers.Dense(100, activation='relu')\n",
    "        #self.dropout_1    = tf.keras.layers.Dropout(self.dropout_rate)\n",
    "        self.layer_2      = tf.keras.layers.Dense(64 , activation='relu')\n",
    "        self.dropout_2    = tf.keras.layers.Dropout(self.dropout_rate)\n",
    "        self.layer_3      = tf.keras.layers.Dense(32 , activation='relu')\n",
    "        self.dropout_3    = tf.keras.layers.Dropout(self.dropout_rate)\n",
    "        self.output_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        # 'DAY_OF_WEEK', 'HOUR_OF_DAY', 'MINUTE_OF_HOUR', 'SECOND_OF_MINUTE', 'TIME',\n",
    "        # 'BUS_ID', 'BUSROUTE_ID', 'BUSSTOP_ID', 'ROUTE_TIME', 'SEQ_NUM'\n",
    "        days_of_week      = inputs[:, 0]\n",
    "        hours_of_day      = inputs[:, 1]\n",
    "        minutes_of_hour   = inputs[:, 2]\n",
    "        seconds_of_minute = inputs[:, 3]\n",
    "        time_positions    = inputs[:, 4]\n",
    "        bus_ids           = inputs[:, 5]\n",
    "        route_ids         = inputs[:, 6]\n",
    "        busstop_ids       = inputs[:, 7]\n",
    "        route_times       = inputs[:, 8]\n",
    "        seq_nums          = inputs[:, 9]\n",
    "\n",
    "        day_vectors     = self.day_embedding    (tf.cast(days_of_week     , dtype=tf.int32))\n",
    "        hour_vectors    = self.hour_embedding   (tf.cast(hours_of_day     , dtype=tf.int32))\n",
    "        minute_vectors  = self.minute_embedding (tf.cast(minutes_of_hour  , dtype=tf.int32))\n",
    "        second_vectors  = self.second_embedding (tf.cast(seconds_of_minute, dtype=tf.int32))\n",
    "        time_vectors    = self.time_embedding   (tf.cast(time_positions   , dtype=tf.int32))\n",
    "        \n",
    "        bus_vectors     = self.bus_embedding    (tf.cast(bus_ids    , dtype=tf.int32))\n",
    "        route_vectors   = self.route_embedding  (tf.cast(route_ids  , dtype=tf.int32))\n",
    "        busstop_vectors = self.busstop_embedding(tf.cast(busstop_ids, dtype=tf.int32))\n",
    "        \n",
    "        temporal_features =  tf.math.add(\n",
    "            tf.concat([day_vectors, hour_vectors, minute_vectors, second_vectors], 1),\n",
    "            time_vectors\n",
    "        )\n",
    "        #print(temporal_features.shape)\n",
    "\n",
    "        concatted_input = tf.concat([\n",
    "            temporal_features, \n",
    "            bus_vectors      , \n",
    "            route_vectors    , \n",
    "            busstop_vectors\n",
    "        ], 1)\n",
    "        #print(concatted_input.shape)\n",
    "        \n",
    "        x = self.layer_1(concatted_input)\n",
    "        #print(x.shape)\n",
    "        x = tf.concat([\n",
    "            x, \n",
    "            tf.reshape(route_times, [route_times.shape[0], 1]),\n",
    "            tf.reshape(seq_nums   , [seq_nums.shape   [0], 1])\n",
    "        ], 1) # scaling factor\n",
    "        #print(x.shape)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.dropout_2(x, training=training)\n",
    "        x = self.layer_3(x)\n",
    "        x = self.dropout_3(x, training=training)\n",
    "\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = tf.constant([\n",
    "    [1, 2, 3],\n",
    "    [2, 3, 4],\n",
    "])\n",
    "a = tf.constant([2, 3])\n",
    "b = tf.constant([4, 5])\n",
    "print(t.shape, a.shape, b.shape)\n",
    "print(tf.reshape(a, [a.shape[0], 1]))\n",
    "\n",
    "c = tf.concat([t, tf.reshape(a, [a.shape[0], 1]), tf.reshape(b, [b.shape[0], 1])], 1)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#del model\n",
    "model = BusNet()\n",
    "model(np.array([train_input.iloc[0].values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_object    = tf.keras.losses.MeanSquaredError()\n",
    "optimizer      = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss     = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.MeanAbsoluteError(name='train_accuracy')\n",
    "\n",
    "test_loss      = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy  = tf.keras.metrics.MeanAbsoluteError(name='test_accuracy')\n",
    "\n",
    "ckpt    = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, net=model)\n",
    "manager = tf.train.CheckpointManager(ckpt, './busnet_checkpoints', max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_batch, label_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(input_batch, training=True)\n",
    "        loss        = loss_object(label_batch, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(label_batch, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(input_batch, label_batch):\n",
    "    predictions = model(input_batch, training=False)\n",
    "    t_loss      = loss_object(label_batch, predictions)\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(label_batch, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ckpt.restore(manager.latest_checkpoint)\n",
    "if manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "else:\n",
    "    print(\"Initializing from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs     = 15\n",
    "batch_size = 256\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    print(\"starting of epoch\", epoch)\n",
    "    for step, (t_input, t_target) in enumerate(training_dataset.batch(batch_size)):\n",
    "        train_step(tf.cast(t_input, dtype=tf.float32), t_target)\n",
    "        if step % 200 == 0:\n",
    "            print(\"epoch:\", epoch, \"step:\", step, \"training loss\", float(train_loss.result()), \"training accuracy\", float(train_accuracy.result()))\n",
    "\n",
    "            ckpt.step.assign_add(1)\n",
    "        if int(ckpt.step) % 400 == 0:\n",
    "            save_path = manager.save()\n",
    "            print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n",
    "            \n",
    "        if step % 2000 == 0:\n",
    "            print(\"evaluating on test data...\")\n",
    "            test_loss.reset_states()\n",
    "            test_accuracy.reset_states()\n",
    "            for t_step, (t_input, t_target) in enumerate(testing_dataset.shuffle(buffer_size=250).batch(batch_size)):\n",
    "                test_step(tf.cast(t_input, dtype=tf.float32), t_target)\n",
    "                if t_step%40==0 and t_step!=0:\n",
    "                    break\n",
    "            print(\"test data result => testing loss\", float(test_loss.result()), \"testing accuracy\", float(test_accuracy.result()))\n",
    "            print(\"back to training...\")\n",
    "    print(epoch, \"is done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
